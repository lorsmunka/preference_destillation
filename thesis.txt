Domain Specifikus LLM Desztillációs Pipeline

Abstract
Sok feladatra szeretnénk az LLM-ek általános intelligenciáját alkalmazni. Gyakran használt LLM alapú ágensrendszereknél (pl.: döntési pontok) és strukturált output generálásnál (pl.: text sentiment classification) hasznos lehet egy desztillációs optimalizálást végrehajtani, hiszen az adott feladatot akár 10-100-szor hatékonyabban fogja tudni elvégezni a desztillált modell. A dolgozat vizsgálja az ilyen rendszerek generalizált megvalósíthatóságát, illetve olyan optimalizációs eszközöket használ, mint a csökkentett kimeneti szótár, csökkentett kontextusméret és csökkentett paraméterszám. A tanítás során egy kisebb transformer modell kerül betanításra curriculum traininget alkalmazva, ahol a modell többfajta loss metrika (Kullback-Leibler divergencia, cross entropy) arányváltozásán keresztül tanul: először a tanármodell eloszlását, majd a következő token pontos eltalálására fektet nagyobb hangsúlyt. A gradiensben végig megjelenik mindkét loss. Az ilyen optimalizálások elérhetővé tehetik nagyobb modellek domain-specifikus tudását akár consumer grade hardveren, vagy jelentősen csökkenthetik az LLM-ek vállalati felhasználási költségeit, miközben a válaszidő is javulhat.

1. Bevezetés
TODO

2. Implementáció
A projekt 3 részre bontható: data extraction pipeline, tanítás és a modell(ek). A data extraction pipeline egy tanármodellt használva állítja elő és menti el a desztillációs tanításhoz szükséges adatokat (ami akár több modell tanításához is újrahasználható). A tanítás és modell jobban összefügg, a tanítás egy speciális curriculum, amely célja először a teacher modell következő token predikció disztribúciójának a student modellhez való közelítése, majd ezt követően a következő helyes token fontosságára nagyobb hangsúlyt fektetve megerősíteni a modellt, hogy ne csak hasonlóan gondolkodjon, mint a teacher modell, de a helyes döntést is hozza meg. Több fajta student modellt is lehet használni, a dolgozat viszont elsősorban kisebb multi-headed attentiont használó Transformer modellekre fog fókuszálni, amelyek ugyanazzal az autoregresszív viselkedéssel állítják elő a kimeneti választ, mint a manapság leginkább elterjedt nagy nyelvi modellek (pl.: OpenAI GPT, Google Gemini, Anthropic Claude modellek) és a desztillációhoz használt teacher modellek maguk is.

2.1 Példa
A projektet számos feladat optimalizálására lehet használni, ügyfélszolgálati emailek automatikus LLM-ekkel történő osztályozásától, online fórumokon autómoderálásán keresztül, ágensalapú workflow-okig. A dolgozat során Reddit komment sentiment analízisét fogom példának használni, vagyis a feladat az, hogy egy beérkező Reddit kommentet JSON objektummal jellemezze a modell (példa: 1. kép).


1. Kép

2.2 Data extraction pipeline
A projekt során a Google Gemma 3 4b open source modellt használtam mint teacher. A modell méretéhez képest elfogadható intelligenciával rendelkezik, képes megbízhatóan structured outputot (JSON) előállítani. Mérete miatt kényelmesen elfér 12GB VRAM-on, és consumer grade videókártyán jó sebességgel használható inferenciára. A projektben csak a 3 és 25 token hosszúságú, speciális tageket és URL-eket nem tartalmazó kommenteket vizsgáltam. A 3 és 25 token közötti mondatok vizsgálata előre ismertté teszi a maximum context lengthet, így ez is használható az optimalizálás során. A tagek és URL-ek nem figyelembevétele pedig azért szükséges, hogy a modellek ne kapjanak zavaró, félrevezető adatokat.
A mondatokat Gemma 3 4b klasszifikálja, és a klasszifikálás során minden autoregresszív lépésnél mentésre kerülnek a szükséges és auxiliary tokenek nyers logit értékei. A szükséges tokenek azok a tokenek, amelyek abszolút szükségesek az összes lehetséges valid JSON generálásához (32 token), míg az auxiliary tokenek csupán azt a célt szolgálják, hogy a desztilláció során nagyobb puha címkét biztosítsanak a student modellnek, így jobban el tudja a student sajátítani a teacher gondolkodását (278 token). Tehát egy klasszifikációs példa generálása során 37-42 lépés történik, és minden egyes lépésnél mentésre kerül a teacher modell 300 figyelt token nyers logit eloszlása. Ezek a példák 128-asával mentésre kerülnek egy JSONL batchbe.
Az, hogy Gemma 3 4b viszonylag gyakran félreklasszifikál mondatokat, nem jelent problémát, hiszen nem azt szeretném bizonyítani, hogy a desztillált modell emberi szempontból helyes választ adott-e, hanem hogy mennyire tudja a student modell követni a teacher modell preferenciáját.
Gemma 3 4b egy felső középkategóriás gépen, egy Nvidia RTX 4070-es videókártyán torch.bfloat16 pontossággal 58-62 másodperc alatt generál 32 példát, példánként átlagosan 40 lépéssel.
2.3 A tanítás
A tanítás egyik legfontosabb része a veszteség, amit használva a modell optimalizál. A projekt két veszteség együttesét használja, változó arányban. A Kullback-Leibler divergencia veszteség két valószínűségi eloszlás közötti különbséget számol, tehát azt mondja meg, hogy a teacher és a student modell mennyire gondolkodnak hasonlóan. A student modell nem csak a helyes választ látja, de a teacher modell eloszlásából a bizonyosságot is, így a sokkal információgazdagabb példából tud a modell tanulni. A tanítás későbbi részében a cross entropy loss kap nagyobb hangsúlyt, amely a helyes következő tokenre optimalizál. A KL divergencia veszteség szerepe elsősorban, hogy gyorsabban tudjon a modell tanulni, kevesebb adatra és tanítási időre legyen szükség. A végső célt azonban, a helyes következő token predikciót a CE loss fogja megerősíteni. A tanítás elején 80%-20% arányban van KL és CE veszteség használva, a tanítás végén az arány megfordul, 20%-80%-ra. Az arány változása lineárisan változik. Mindkét veszteség végig jelen van a gradiensben, így stabilabb a tanulás.
Nagy nyelvi modelleknél szinte kizárólagosan AdamW-t használnak optimizerként, hiszen stabilabb tanulást eredményez (főleg nagyobb modelleknél) és jobban kezeli a sparse adatokat (mint például a nyelv). Ráadásul a modern AI/LLM infrastruktúra többnyire erre az optimizerre van optimalizálva, ez az industry standard.
Hogy a modell kezdetben gyorsabban tudjon tanulni, illetve legyen lehetősége fine-tuneolni a tanítás végére, Cosine Annealinget használtam Learning Rate Schedulernek.
A tanítás folyamán folyamatosan látjuk a konzolon a train losst, a train accuracyt és az adott példa vagy batch idejét. Ezeknek az adatoknak a fontosabb része mentésre is kerül.
Minden epoch végén készül checkpoint és tesztelésre kerül a modell a teljes adathalmaz 10%-án, ami erre a célra lett félretéve.
A program kezeli a graceful shutdownt, tehát epochok között is el tudja menteni a progresst.
2.4.1 Alap modell
A student modell egy 200m paraméteres Transformer architektúrájú modellből és 270m embeddingből áll. A modell bemeneti szótára megegyezik Gemma 3 4b-vel (nagyjából 255k token) és ugyanazt a tokenizert használja. Így jelen példában minden kommentet, amit Gemma 3 4b ki tud értékelni, a saját modell is. A kimeneti szótára viszont jelentősen le van csökkentve Gemma 3 4b-hez képest, a nagyjából 255k token helyett mindössze 32, input generáláshoz szükséges és 278 auxiliary, tanítást segítő, tehát összesen 300 tokenre korlátozódik. Ez körülbelül ~98,5%-os optimalizálás. A saját modellnek a context length-je 75-re van csökkentve, hiszen 25 lehet a maximum hossza a vizsgált Reddit kommentnek és maximum 50 hosszú lehet a generált JSON output. Gemma 3 4b-nek 128k a context windowja, tehát 99,5%-os az optimalizálás.
A teacher modell 4000 millió, vagyis 4 milliárd paraméterszámú, a saját modell 200 millió, tehát egy 20x kisebb modellt kapunk eredményül, ami a kisebb context length miatt több paramétert jelent beolvasott tokenekre. Illetve a modellnek csak egy részét kell tudni annak, amit a teachernek. Ez a különbség tükröződik is TPS-ben (Tokens per second). Egy MacBook Pro M1 Pro 32GB rendszeren Gemma 3 4b 1,7 TPS teljesítményt ér el, míg a saját modell 12,5 TPS-t tudott elérni. Ráadásul ez a méretbeli különbség határozhatja meg, hogy például egy telefonon, vagy régebbi generációs hardveren lehet-e a modellt ésszerű keretek között futtatni.
A modellnek a hidden dimensionja 1024, fele Gemma 3 4b-nek, de továbbra is gazdag reprezentációt biztosítva.
A modellnek 16 rétege van és rétegenként 16 attention headje. A modell paramétereinek nagy része a feed forward MLP rétegekben van (130m), míg a figyelem fejeknek 70m paraméter van allokálva.
Aktivációs függvényként GeLU-t használtam, ez a népszerű ReLU függvények egy folyamatos verziója, gyakran használt LLM-eknél és transformereknél.
3 Módszertan
3.1 Pilot run
A teljes modell betanítások előtt saját hardveren is futattam egy 97 órás training runt. Ezzel párhuzamosan generáltam az adatokat (összesen további 11 óra alatt), hogy lássam, hogy a kódom is jól működik és a modell is elkezd-e konvergálni. Az első 10 epochot az első 10 batch adaton tette a modell. Ez 10-szer 32 példamondat 40 lépését jelenti. Ekkor még csak KL divergencia veszteséget használtam. Az első pár példa 4,5 körüli értékéről hamar lement (pár 10 példa) az 1,1-1,4 közötti sávra. A modell ebben az időszakban 8% pontossággal találta el a következő tokent. A loss folyamatosan csökkent, illetve a 10. epoch után folyamatosan növeltem a train datasetet, 50, 100 majd 250 batchre.
Az utolsó 2 epochig nem volt megfigyelhető a túltanulás, a train loss mindig magasabb volt, mint az epoch végére előálló modell teszt lossa.
Körülbelül a ~15. epochban (ekkor már ~300 batch adaton tanult a modell) bevezetésre került a CE loss is, és ezután egyre nagyobb hangsúlyt kapott, hogy a modell pontosabban tudja a következő tokent megbecsülni. A CE loss alapból viszonylag alacsony értéken kezdett, és nem volt hirtelen kiugró loss csökkenés a bevezetés után, ez azt sugallja, hogy a KL loss alapból hasonló irányba vitte a modellt, mint ami CE lossnak az optimumja, tehát a desztilláció ilyen szempontból működött.
A modell összesen 20 epochot ment, az utolsó 3-ban 500 batch adaton tanult már. A loss még mindig folyamatosan csökkent, viszont ezek voltak az első epochok, amikor a train loss alacsonyabb volt, mint a test loss, tehát látszólag elkezdődött a túltanulás, a nagy nyelvi modellek nagyságrendjében igencsak kicsinek mondható tanítási adathalmazon. A végső train loss 0,06 - 0,08 körül volt. Az accuracy felment 20% körülre. Megfigyelhető az is, hogy függetlenül a példamondat hosszától, a modell elkezdte megtanulni az első 5-6 tokent, ami szinte mindig ugyanaz a JSON generálásnál, ez valószínűleg részben köszönhető a 13. epochban bevezetett dupla sortörés tokennek, ami a mondatot és generálást elválasztja, illetve mivel állandóan megjelenik a modell kontextusában, minden példában, attention sinkként is használhatja a modell.
3.2 Első eredmények
A pilot run végére 20 epochot tett meg a modell. Minden epoch végén készült egy checkpoint. Nem minden checkpoint között egyforma compute távolság van, hiszen az első 10 epoch csak 10 batch adaton történt. Egy példamondaton, amit a modell látott tanítás közben, a következőképpen javult az accuracy:
0. epoch acc: 0.1184
1. epoch acc: 0.0886
2. epoch acc: 0.0950
3. epoch acc: 0.1256
4. epoch acc: 0.0765
5. epoch acc: 0.1216
6. epoch acc: 0.1176
8. epoch acc: 0.0926
9. epoch acc: 0.0829
10. epoch acc: 0.0636
11. epoch acc: 0.0765
12. epoch acc: 0.0580
15. epoch acc: 0.1908
16 . epoch acc: 0.2077
17. epoch acc: 0.1973
18. epoch acc: 0.2061
19. epoch acc: 0.1924
20. epoch acc: 0.2077

Ez egy reprezentatív példa, példamondatonként eltérhet a pontos accuracy, de jól látható a javuló tendencia.
Példa a JSON generálásra különböző checkpointoknál, ugyanaz a mondat.
1. epoch:
json
json
json
{
    json
    ",
    "sentiment": "neutral",
    ",
    "sentiment",
    
    "sentiment",
    "
5. epoch:
 {
    tone": "
    sentiment": "
    safety": "negativesafety": "
     "    "safety": " " "        safety": " " "toxicity":

10. epoch:
 ```json
```json
{
{
    ": "    
  sentiment": "",
  ": "": "",
}"toxicity": "
}
}":

15. epoch:
 ```json
{
    
  ",
  tone": " "
   " "     "
   " "": "
  ": " " "  ",
  ",

20. epoch:
```json
{
    ": "": "
    ",
    
    ": "
        
    ",
    "toxicity": "
}"
}"
}

Az autoregresszív modelleknél különösen veszélyes az alacsony accuracy, ugyanis ha bármelyik előző token hibásan került generálásra, a modell tanítás során még nem látott ilyen hibásan generált helyes folytatást, és onnantól borulhat a modell teljes válasza. Ennek ellenére is megfigyelhető, hogy ugyanazon a példán a későbbi checkpoint modell generálások több helyes tokent tudják eltalálni, az első 8 token már helyes a 20. epochban, és kezdetleges JSON forma mintázatok is megfigyelhetőek.
3.3 Korai becslés
Saját hardveren (felső középkategóriás gép, RTX 4070 12GB videokártya) a teljes training és adatelőállítási idő 2870 óra lenne.
Az adatbázisban ~500 ezer Reddit komment van, ami megfelel minden kitételnek. Ezekből a példamondatokból saját hardveren (~62 másodperc / 32 példa) optimális esetben 270 óra alatt lehetne egy teljes tanító adatbázist létrehozni.
A "Chinchilla scaling" szerint minden egyes paraméterre 20 tokennyi példa kell a sikeres tanításhoz. Ez 200 millió modell paraméter esetében 4 milliárd tokent jelent, viszont az 500 ezer komment legjobb esetben is csak 20 millió példa. A desztillációból fakadó előnyök és a specifikus domain csökkentett tudásigénye mellett is több mint valószínű, hogy az összes példát fog kelleni használni.
15 epoch 500 ezer példán, példánkénti 1,25 sebességgel ideális esetben is 2600 órányi folyamatos GPU idő.
Tehát a pilot teszt alapján egy modell end-to-end tanítás 2870 óra, vagyis 120 nap, innentől kezdve pedig további modellenként 2600 órával, vagyis 108 nappal kell számolni.

